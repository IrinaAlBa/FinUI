{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92177e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import KDTree\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from scipy import stats\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f763843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radius_kneighbors(x, n_neighbors):\n",
    "    kd = KDTree(x, metric=\"chebyshev\")\n",
    "    neigh_dist = kd.query(x, k=n_neighbors+1)[0]\n",
    "    \n",
    "    return np.nextafter(neigh_dist[:, -1], 0)\n",
    "\n",
    "\n",
    "def num_points_within_radius(x, radius):\n",
    "    kd = KDTree(x, metric=\"chebyshev\")\n",
    "    nx = kd.query_radius(x, radius, count_only=True, return_distance=False)\n",
    "    \n",
    "    return np.array(nx) - 1.0\n",
    "\n",
    "\n",
    "def preprocess_data(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    elif x.ndim != 2:\n",
    "        raise ValueError(f'x.ndim = {x.ndim}, should be 1 or 2')\n",
    "\n",
    "    means = np.maximum(1e-100, np.mean(np.abs(x), axis=0))\n",
    "\n",
    "    return (1/means) * x\n",
    "\n",
    "\n",
    "def compute_mi(x, y, n_neighbors=5):\n",
    "    # Kraskov\n",
    "    n_samples = len(x)\n",
    "    x, y = [preprocess_data(t) for t in [x, y]]\n",
    "    xy = np.hstack((x, y))\n",
    "    k = np.full(n_samples, n_neighbors)\n",
    "    radius = get_radius_kneighbors(xy, n_neighbors)\n",
    "\n",
    "    mask = (radius == 0)\n",
    "    if mask.sum() > 0:\n",
    "        vals, ix, counts = np.unique(\n",
    "            xy[mask], axis=0, return_inverse=True, return_counts=True\n",
    "        )\n",
    "        k[mask] = counts[ix] - 1\n",
    "\n",
    "    nx = num_points_within_radius(x, radius)\n",
    "    ny = num_points_within_radius(y, radius)\n",
    "\n",
    "    mi = max(0, digamma(n_samples) + np.mean(digamma(k))\n",
    "             - np.mean(digamma(nx + 1)) - np.mean(digamma(ny + 1)))\n",
    "    return mi\n",
    "\n",
    "def greedy(x, y, n_neighbors=5):\n",
    "    idx = []\n",
    "    rem = np.arange(0, x.shape[1])\n",
    "    score = 0\n",
    "    j = -1\n",
    "    while len(rem)>0:\n",
    "        mi = np.array([compute_mi(x[:, idx+[i]], y, n_neighbors) for i in rem])\n",
    "        j = rem[np.argmax(mi)]\n",
    "        mi = np.max(mi)\n",
    "        if mi > score:\n",
    "            score = mi\n",
    "            rem = np.delete(rem, j)\n",
    "            idx.append(j)\n",
    "        else:\n",
    "            break\n",
    "        j = -1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv('../datasets/FinUI/100_avg_scores.csv')\n",
    "survey = survey.set_index(np.arange(1, 101))\n",
    "\n",
    "img_features = pd.read_csv('../datasets/FinUI/100_img_features.csv')\n",
    "img_features = img_features.set_index(np.arange(1, 101))\n",
    "\n",
    "txt_features = pd.read_csv('../datasets/FinUI/100_txt_features.csv')\n",
    "txt_features = txt_features.set_index(np.arange(1, 101))\n",
    "\n",
    "ae_features = pd.read_csv('../datasets/FinUI/100_ae_features.csv')\n",
    "ae_features = ae_features.set_index(np.arange(1, 101))\n",
    "\n",
    "aeb_features = pd.read_csv('../datasets/FinUI/100_aeb_features.csv')\n",
    "aeb_features = aeb_features.set_index(np.arange(1, 101))\n",
    "\n",
    "features = ['img_' + f for f  in img_features.columns.to_list()] \\\n",
    "+ ['txt_' + f for f  in txt_features.columns.to_list()] \\\n",
    "+ ['ae_' + f for f  in ae_features.columns.to_list()]\n",
    "\n",
    "questions = survey.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(\n",
    "    np.append(\n",
    "        img_features.fillna(0).values, \n",
    "        txt_features.fillna(0).values, \n",
    "        axis=1\n",
    "    ),\n",
    "    ae_features.fillna(0).values, \n",
    "    axis=1\n",
    ")\n",
    "y = survey.values\n",
    "\n",
    "X_train, y_train = X[:60, :], y[:60, :]\n",
    "X_val, y_val = X[60:80, :], y[60:80, :]\n",
    "X_test, y_test = X[80:, :], y[80:, :]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size = 0.3, random_state = 2\n",
    "# )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a113ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.arange(0.05, 0.23, 0.01)\n",
    "results = {}\n",
    "question = '1_1'\n",
    "mi = []\n",
    "ft = features\n",
    "for f in ft:\n",
    "    mi.append(compute_mi(X_train[:, features.index(f)], y_train[:, questions.index(question)], 5))\n",
    "res_loc = []\n",
    "for thresh in th:\n",
    "    idx = np.array(mi)>thresh\n",
    "    reg = LinearRegression().fit(X_train[:,idx], y_train[:, questions.index(question)])\n",
    "    cc = np.corrcoef(reg.predict(X_val[:,idx]), y_val[:, questions.index(question)])[0, 1]\n",
    "    res_loc.append(cc)\n",
    "\n",
    "thresh = th[np.argmax(np.array(res_loc))]\n",
    "print(thresh, max(res_loc))\n",
    "idx = np.array(mi)>thresh\n",
    "reg = LinearRegression().fit(X_train[:,idx], y_train[:, questions.index(question)])\n",
    "cc = np.corrcoef(reg.predict(X_test[:,idx]), y_test[:, questions.index(question)])[0, 1]\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = reg.predict(X_test[:,idx])\n",
    "z = y_test[:, questions.index(question)]\n",
    "b, m = polyfit(z, prediction, 1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(z, prediction)\n",
    "ax.plot(z, b + m * z, '-', c='b')\n",
    "ax.set_xlabel('Expert Scores', labelpad=10, fontsize=14)\n",
    "ax.set_ylabel('Score Predictions', labelpad=10, fontsize=14)\n",
    "plt.title(f'Question {question}', pad=10, fontsize=14)\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "ax.text(0.05, 0.95, 'œÅ = 0.49', transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb744d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
